{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e7571c",
   "metadata": {},
   "source": [
    "# RAG Confluence Example\n",
    "\n",
    "Rag llama stack example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11258f57-90ed-4ee6-9fad-a762ae234db0",
   "metadata": {},
   "source": [
    "Import relevant modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff7a062-0c78-4a85-90e5-f39bb43530aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/app-root/lib64/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/opt/app-root/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~andas (/opt/app-root/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet llama-stack-client requests markdownify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c811c0-4d46-40c5-895d-bf6245ee27d4",
   "metadata": {},
   "source": [
    "Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2740a6d-15bd-4d32-82ac-637506c84586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid\n",
    "\n",
    "# --- Llama Stack base URL (same as your working sample) ---\n",
    "LLAMA_BASE_URL = os.getenv(\"LLAMA_BASE_URL\", \"http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321\").rstrip(\"/\")\n",
    "\n",
    "# --- Confluence Cloud (Atlassian) ---\n",
    "CONF_CLOUD_ID   = os.getenv(\"CONF_CLOUD_ID\", \"\")       # e.g. \"84927973-adf1-4112-be18-59ea4f9c3d60\"\n",
    "CONF_USER       = os.getenv(\"CONF_USER\", \"\")           # Atlassian account email\n",
    "CONF_API_TOKEN  = os.getenv(\"CONF_API_TOKEN\", \"\")      # Atlassian API token\n",
    "\n",
    "# Ingest ONLY this Confluence space (by human-friendly name)\n",
    "SPACE_NAME  = os.getenv(\"SPACE_NAME\", \"Known Issues\").strip()\n",
    "\n",
    "# Stable vector DB/collection name for this Confluence space\n",
    "VECTOR_DB_ID = os.getenv(\"VECTOR_DB_ID\", \"conf-known-issues\")\n",
    "\n",
    "# --- Simple filters (optional) ---\n",
    "SPACE_KEYS  = [s.strip() for s in os.getenv(\"SPACE_KEYS\", \"KI\").split(\",\") if s.strip()]\n",
    "LABELS      = [s.strip() for s in os.getenv(\"LABELS\", \"\").split(\",\") if s.strip()]\n",
    "SINCE_HOURS = int(os.getenv(\"SINCE_HOURS\", \"0\"))     # last 7 days by default\n",
    "\n",
    "assert CONF_CLOUD_ID and CONF_USER and CONF_API_TOKEN, \"Please set CONF_CLOUD_ID, CONF_USER and CONF_API_TOKEN\"\n",
    "assert SPACE_NAME, \"Please set SPACE_NAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a879aa-1c39-4eac-a70e-069758ddd475",
   "metadata": {},
   "source": [
    "Cell 3 — imports + lightweight helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa42c4c-d5e8-4b25-b50b-6e2d6f957ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import LlamaStackClient, Agent\n",
    "from llama_stack_client.types import Document\n",
    "import requests, uuid, re\n",
    "from markdownify import markdownify as html2md\n",
    "from pathlib import Path\n",
    "from llama_stack_client import AgentEventLogger\n",
    "\n",
    "client = LlamaStackClient(base_url=LLAMA_BASE_URL)\n",
    "\n",
    "def conf_session(user, token):\n",
    "    s = requests.Session()\n",
    "    s.auth = (user, token)\n",
    "    s.headers.update({\"Accept\": \"application/json\"})\n",
    "    return s\n",
    "\n",
    "def resolve_space_key_by_name(session, cloud_id, space_name):\n",
    "    \"\"\"\n",
    "    Return the first space 'key' whose 'name' matches (case-insensitive).\n",
    "    \"\"\"\n",
    "    api_base = f\"https://api.atlassian.com/ex/confluence/{cloud_id}/wiki/rest/api\"\n",
    "    url = f\"{api_base}/space\"\n",
    "    start = 0\n",
    "    limit = 50\n",
    "    name_lc = space_name.strip().lower()\n",
    "    while True:\n",
    "        resp = session.get(url, params={\"start\": start, \"limit\": limit}, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        for sp in results:\n",
    "            if str(sp.get(\"name\",\"\")).strip().lower() == name_lc:\n",
    "                return sp.get(\"key\")\n",
    "        if len(results) < limit:\n",
    "            break\n",
    "        start += len(results)\n",
    "    return None\n",
    "\n",
    "def build_cql(space_key, labels, since_hours):\n",
    "    parts = [\"type=page\"]\n",
    "    if since_hours and since_hours > 0:\n",
    "        parts.append(f'lastmodified > now(\"-{since_hours}h\")')\n",
    "    if space_key:\n",
    "        parts.append(f'space=\"{space_key}\"')\n",
    "    if labels:\n",
    "        parts.append(\"(\" + \" OR \".join([f'label=\"{l}\"' for l in labels]) + \")\")\n",
    "    return \" and \".join(parts)\n",
    "\n",
    "def conf_search_pages(session, cloud_id, cql, limit=50):\n",
    "    api_base = f\"https://api.atlassian.com/ex/confluence/{cloud_id}/wiki/rest/api\"\n",
    "    url = f\"{api_base}/content/search\"\n",
    "    start = 0\n",
    "    while True:\n",
    "        resp = session.get(url, params={\n",
    "            \"cql\": cql,\n",
    "            \"limit\": limit,\n",
    "            \"start\": start,\n",
    "            \"expand\": \"body.export_view,version,metadata.labels,space,history.lastUpdated\",\n",
    "        }, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            break\n",
    "        for it in results:\n",
    "            yield it\n",
    "        if len(results) < limit:\n",
    "            break\n",
    "        start += len(results)\n",
    "\n",
    "def html_to_markdown(html: str) -> str:\n",
    "    md = html_to_md = html2md(html or \"\", strip=['script', 'style'])\n",
    "    md = re.sub(r\"\\s+\\n\", \"\\n\", md)\n",
    "    md = re.sub(r\"\\n{3,}\", \"\\n\\n\", md)\n",
    "    return md.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39020dcc-a903-4e66-b3af-808846aca502",
   "metadata": {},
   "source": [
    "Cell 4 — discover models + create a fresh vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07b82a1-11d8-4095-9724-b59f6e087c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved vector DB not found; will register a new one.\n",
      "Created vector DB: vs_15c9ad54-989d-4d1b-9a81-3bbb13f25b33 (embedding_model=granite-embedding-125m) and saved to conf_known_issues.vdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vs_15c9ad54-989d-4d1b-9a81-3bbb13f25b33'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VDB_ID_FILE = Path(\"conf_known_issues.vdb\")\n",
    "\n",
    "# 1) If we’ve saved a real ID before, reuse it (and verify it still exists)\n",
    "saved_id = VDB_ID_FILE.read_text().strip() if VDB_ID_FILE.exists() else None\n",
    "vector_db_id = None\n",
    "\n",
    "if saved_id:\n",
    "    try:\n",
    "        # Ensure it still exists\n",
    "        vdbs = list(client.vector_dbs.list())\n",
    "        match = next((v for v in vdbs if getattr(v, \"identifier\", None) == saved_id), None)\n",
    "        if match:\n",
    "            vector_db_id = match.identifier\n",
    "            print(f\"Reusing saved vector DB: {vector_db_id}\")\n",
    "        else:\n",
    "            print(\"Saved vector DB not found; will register a new one.\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: could not list vector DBs; will try register:\", e)\n",
    "\n",
    "# 2) If not found, create and save\n",
    "if not vector_db_id:\n",
    "    embed = next(m for m in client.models.list() if m.model_type == \"embedding\")\n",
    "    vdb = client.vector_dbs.register(\n",
    "        vector_db_id=VECTOR_DB_ID,   # may be ignored; server can mint its own id\n",
    "        embedding_model=embed.identifier,\n",
    "    )\n",
    "    vector_db_id = vdb.identifier\n",
    "    VDB_ID_FILE.write_text(vector_db_id)\n",
    "    print(f\"Created vector DB: {vector_db_id} (embedding_model={embed.identifier}) and saved to {VDB_ID_FILE.name}\")\n",
    "\n",
    "vector_db_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3972ea-39f7-4324-8700-939b4b58643d",
   "metadata": {},
   "source": [
    "Cell 5 — fetch Confluence pages and prepare Documents (one per page)\n",
    "\n",
    "Keep it simple: we let Llama Stack do chunking via chunk_size_in_tokens at insert time, so we just send whole pages as single Documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825c191f-bb2a-4b8b-835e-2be396b56efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACE_NAME: Known Issues\n",
      "SPACE_KEY:  KI\n",
      "CQL:        type=page and space=\"KI\"\n",
      "Prepared 5 Confluence pages from space 'Known Issues'\n"
     ]
    }
   ],
   "source": [
    "sess = conf_session(CONF_USER, CONF_API_TOKEN)\n",
    "\n",
    "space_key = resolve_space_key_by_name(sess, CONF_CLOUD_ID, SPACE_NAME)\n",
    "assert space_key, f\"Space named '{SPACE_NAME}' not found. Check spelling/case or your permissions.\"\n",
    "\n",
    "cql = build_cql(space_key, LABELS, SINCE_HOURS)\n",
    "print(\"SPACE_NAME:\", SPACE_NAME)\n",
    "print(\"SPACE_KEY: \", space_key)\n",
    "print(\"CQL:       \", cql)\n",
    "\n",
    "documents = []\n",
    "count = 0\n",
    "\n",
    "for page in conf_search_pages(sess, CONF_CLOUD_ID, cql):\n",
    "    pid   = page.get(\"id\")\n",
    "    title = page.get(\"title\", \"\")\n",
    "    body_html = (((page.get(\"body\") or {}).get(\"export_view\") or {}).get(\"value\")) or \"\"\n",
    "    space_key = ((page.get(\"space\") or {}).get(\"key\")) or \"\"\n",
    "    url = f\"https://api.atlassian.com/ex/confluence/{CONF_CLOUD_ID}/wiki/rest/api/content/{pid}\"\n",
    "\n",
    "    md = html_to_markdown(body_html)\n",
    "    if not md:\n",
    "        continue\n",
    "\n",
    "    documents.append(\n",
    "        Document(\n",
    "            document_id=f\"conf-{pid}\",\n",
    "            content=md,\n",
    "            mime_type=\"text/markdown\",\n",
    "            metadata={\n",
    "                \"source\": \"confluence\",\n",
    "                \"source_url\": url,\n",
    "                \"title\": title,\n",
    "                \"space_key\": space_key,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    count += 1\n",
    "\n",
    "print(f\"Prepared {count} Confluence pages from space '{SPACE_NAME}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d9a7b-8ca3-47ec-a8e7-fe9ca6be0b5c",
   "metadata": {},
   "source": [
    "Cell 6 — insert into vector DB (server-side chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1debfe7-b6fb-4f2c-84b9-788f3ce7f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/tool-runtime/rag-tool/insert \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5 documents into vs_15c9ad54-989d-4d1b-9a81-3bbb13f25b33\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    client.tool_runtime.rag_tool.insert(\n",
    "        documents=documents,\n",
    "        vector_db_id=vector_db_id,\n",
    "        # Let the server chunk; adjust to taste:\n",
    "        chunk_size_in_tokens=512,\n",
    "    )\n",
    "    print(f\"Inserted {len(documents)} documents into {vector_db_id}\")\n",
    "else:\n",
    "    print(\"No documents to insert (check your filters/CQL).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bff797-ae35-4651-8307-ff371223fd26",
   "metadata": {},
   "source": [
    "Cell 7 — pick an LLM and create a tiny RAG agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168209da-a1be-49c7-92af-08cf799750c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/agents \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/tools?toolgroup_id=builtin%3A%3Arag%2Fknowledge_search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/agents/ba39652b-88cc-4d09-a25d-204756f823b9/session \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: vllm-inference/llama-4-scout-17b-16e-w4a16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'393c2b91-3391-43f4-b9ea-4963745876f6'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose an LLM served by vLLM (same pattern as your working sample)\n",
    "llm = next(m for m in client.models.list() if m.model_type == \"llm\" and m.provider_id == \"vllm-inference\")\n",
    "model_id = llm.identifier\n",
    "print(\"Using model:\", model_id)\n",
    "\n",
    "rag_agent = Agent(\n",
    "    client,\n",
    "    model=model_id,\n",
    "    instructions=(\n",
    "        \"You are a helpful assistant. Use the RAG tool. \"\n",
    "        \"Cite source_url(s) when you use retrieved info.\"\n",
    "    ),\n",
    "    tools=[{\n",
    "        \"name\": \"builtin::rag/knowledge_search\",\n",
    "        \"args\": {\"vector_db_ids\": [vector_db_id]}\n",
    "    }],\n",
    ")\n",
    "\n",
    "session_id = rag_agent.create_session(session_name=f\"s{uuid.uuid4().hex}\")\n",
    "session_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92961de5-1eff-4682-ae08-18d2621f242b",
   "metadata": {},
   "source": [
    "Cell 8 — ask something and print a short answer with citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4448fd23-a1ea-4e3f-bd38-38f3130bb862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-inline-service.default.svc.cluster.local:8321/v1/agents/ba39652b-88cc-4d09-a25d-204756f823b9/session/393c2b91-3391-43f4-b9ea-4963745876f6/turn \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user> Summarise the resolution for when Disk full on /var. Get the information from our Confluence docs.\n",
      "\u001b[33minference> \u001b[0m\u001b[33m\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:knowledge_search Args:{'query': 'Disk full on /var resolution Confluence docs'}\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:knowledge_search Response:[TextContentItem(text='knowledge_search tool found 5 chunks:\\nBEGIN of knowledge_search tool results.\\n', type='text'), TextContentItem(text='Result 1\\nContent: a08ad97bfa1)\\n* [Disk full on /var causes 500s & logging failures](/wiki/spaces/KI/pages/15400972/Disk+full+on+var+causes+500s+logging+failures \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\n* [Known Issues](/wiki/spaces/KI/overview \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\nMetadata: {\\'chunk_id\\': \\'ffb8e547-ea03-0714-5d63-d8390b1c4618\\', \\'document_id\\': \\'file-8bf12eb6c3ae4a7fac640b4a32921b3a\\', \\'source\\': \\'confluence\\', \\'source_url\\': \\'https://api.atlassian.com/ex/confluence/84927973-adf1-4112-be18-59ea4f9c3d60/wiki/rest/api/content/15499522\\', \\'title\\': \\'Known Issues\\', \\'space_key\\': \\'KI\\'}\\n', type='text'), TextContentItem(text=\"Result 2\\nContent: **Status:** Active\\u2003**Severity:** High\\u2003**Owner:** SRE\\n**First Seen:** 2025-08-15\\u2003**Last Updated:** 2025-09-03\\n**Tags:** `filesystem` `disk-full` `logging`\\nSummary\\n-------\\n`/var` reached 100% due to runaway debug logs; NGINX couldn’t write logs/temp files, resulting in intermittent 500s.\\nImpact\\n------\\n* **Hosts:** `web-p01`–`web-p04`\\n* **User/Error:** Spikes of HTTP 500; access log gaps.\\nSymptoms\\n--------\\n* `no space left on device` in logs.\\n* `df -h` shows `/var` full.\\nRCA\\n---\\n* Debug logging produced high volume.\\n* Logrotate misconfigured; small partition.\\nResolution\\n----------\\n```\\ntruncate -s 0 /var/log/nginx/access.log\\nlogrotate -f /etc/logrotate.d/nginx\\nsystemctl reload nginx\\n```\\nDisable noisy logging and archive old logs.\\nPrevention\\n----------\\n* Disk alerts at 70/85/95%.\\n* Correct logrotate settings.\\n* Separate partition for logs.\\nMetadata: {'chunk_id': 'b7d8de02-119d-8c35-207d-cac024e33b16', 'document_id': 'file-ffcbcd6b083b4a2c990f8d031946d7a6', 'source': 'confluence', 'source_url': 'https://api.atlassian.com/ex/confluence/84927973-adf1-4112-be18-59ea4f9c3d60/wiki/rest/api/content/15400972', 'title': 'Disk full on /var causes 500s & logging failures', 'space_key': 'KI'}\\n\", type='text'), TextContentItem(text='Result 3\\nContent: Description\\n-----------\\nIn a sentence or two, describe the purpose of this space.\\nSearch this Space\\n-----------------\\nSearch\\nFilter by Label\\n---------------\\nThese are all the labels in use in this space. Select a label to see a list of content the label has been applied to.\\nLabel list\\n----------\\nAs you and your team label content this area will fill up and display the latest updates.\\nRecently updated content\\n------------------------\\nThis list below will automatically update each time somebody in your space creates or updates content.\\n* [Too many open files (EMFILE) causing socket failures](/wiki/spaces/KI/pages/15466552/Too+many+open+files+EMFILE+causing+socket+failures \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\n* [NGINX 502/504 due to upstream timeout](/wiki/spaces/KI/pages/15499574/NGINX+502+504+due+to+upstream+timeout \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\n* [NGINX serving expired/invalid TLS cert](/wiki/spaces/KI/pages/15466527/NGINX+serving+expired+invalid+TLS+cert \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\n* [Disk full on /var causes 500s & logging failures](/wiki/spaces/KI/pages/15400972/Disk+full+on+var+causes+500s+logging+failures \"Known Issues\")\\n  Oct 21, 2025 • contributed by [Chris Renwick](/wiki/display/~70121%3A4d81fc9f-3b77-4a63-ba64-2a08ad97bfa1)\\n* [Known Issues](/wiki/spaces/KI/overview \"Known Issues\")\\n  Oct\\nMetadata: {\\'chunk_id\\': \\'74685299-d4a7-2af2-bec0-d90653063170\\', \\'document_id\\': \\'file-8bf12eb6c3ae4a7fac640b4a32921b3a\\', \\'source\\': \\'confluence\\', \\'source_url\\': \\'https://api.atlassian.com/ex/confluence/84927973-adf1-4112-be18-59ea4f9c3d60/wiki/rest/api/content/15499522\\', \\'title\\': \\'Known Issues\\', \\'space_key\\': \\'KI\\'}\\n', type='text'), TextContentItem(text=\"Result 4\\nContent: **Status:** Active\\u2003**Severity:** Critical\\u2003**Owner:** Platform Eng\\n**First Seen:** 2025-08-30\\u2003**Last Updated:** 2025-09-03\\n**Tags:** `ulimit` `fds` `nginx` `connections`\\nSummary\\n-------\\nTraffic spike exhausted file descriptors; NGINX hit `EMFILE`, dropping connections with 502s.\\nImpact\\n------\\n* **Endpoint:** `auth.example.com`\\n* **User/Error:** Login failures; increased retries.\\nSymptoms\\n--------\\n* NGINX error: `accept4() failed (24: Too many open files)`\\n* `ulimit -n` = 1024; many sockets in `TIME_WAIT`.\\nRCA\\n---\\n* Low `nofile` limit.\\n* Poor connection reuse; keepalive disabled.\\nResolution\\n----------\\n```\\n# /etc/security/limits.d/nginx.conf\\nnginx soft nofile 65536\\nnginx hard nofile 65536\\n```\\n```\\nworker_rlimit_nofile 65536;\\nworker_connections   32768;\\nkeepalive_timeout    65;\\n```\\n```\\nsystemctl daemon-reexec && systemctl restart nginx\\n```\\nPrevention\\n----------\\n* Load test file descriptor usage.\\n* Enable keepalive + upstream pooling.\\n* Alert on `accept4 EMFILE` and high `TIME_WAIT`.\\nMetadata: {'chunk_id': 'b7ecbfc0-8317-51f4-f7bf-fde94521adbb', 'document_id': 'file-43567946200845b6861991f6f858593a', 'source': 'confluence', 'source_url': 'https://api.atlassian.com/ex/confluence/84927973-adf1-4112-be18-59ea4f9c3d60/wiki/rest/api/content/15466552', 'title': 'Too many open files (EMFILE) causing socket failures', 'space_key': 'KI'}\\n\", type='text'), TextContentItem(text=\"Result 5\\nContent: **Status:** Active\\u2003**Severity:** High\\u2003**Owner:** Platform Eng\\n**First Seen:** 2025-08-27\\u2003**Last Updated:** 2025-09-03\\n**Tags:** `nginx` `timeout` `upstream` `deploy`\\nSummary\\n-------\\nAfter a deploy, upstream response latency exceeded `proxy_read_timeout`, causing 502/504 errors for ~42 minutes.\\nImpact\\n------\\n* **Endpoints:** `api.example.com` (Prod)\\n* **User/Error:** 14% of requests failed.\\nSymptoms\\n--------\\n* NGINX error log: `upstream timed out (110: Connection timed out)`\\n* Latency p95 > 30s while NGINX timeout was 15s.\\nRCA\\n---\\n* Too-low timeout vs new upstream latency.\\n* Autoscaler lagged; no health checks.\\nResolution\\n----------\\nRaise timeouts, scale upstream:\\n```\\nproxy_read_timeout 60s;\\n```\\n```\\nkubectl scale deploy upstream-api --replicas=12\\nnginx -t && systemctl reload nginx\\n```\\nPrevention\\n----------\\n* Autoscale on latency/queue depth.\\n* Canary checks on `/healthz`.\\n* Alert on p95 latency thresholds.\\nMetadata: {'chunk_id': '5744863d-d530-eda3-f9a7-7252e977e01f', 'document_id': 'file-bec763f1c8e741cca30b6dad2c8b3b49', 'source': 'confluence', 'source_url': 'https://api.atlassian.com/ex/confluence/84927973-adf1-4112-be18-59ea4f9c3d60/wiki/rest/api/content/15499574', 'title': 'NGINX 502/504 due to upstream timeout', 'space_key': 'KI'}\\n\", type='text'), TextContentItem(text='END of knowledge_search tool results.\\n', type='text'), TextContentItem(text='The above results were retrieved to help answer the user\\'s query: \"Disk full on /var resolution Confluence docs\". Use them as supporting information only in answering this query.\\n', type='text')]\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m\u001b[0m\u001b[33mThe\u001b[0m\u001b[33m resolution\u001b[0m\u001b[33m for\u001b[0m\u001b[33m when\u001b[0m\u001b[33m the\u001b[0m\u001b[33m disk\u001b[0m\u001b[33m is\u001b[0m\u001b[33m full\u001b[0m\u001b[33m on\u001b[0m\u001b[33m /\u001b[0m\u001b[33mvar\u001b[0m\u001b[33m,\u001b[0m\u001b[33m as\u001b[0m\u001b[33m per\u001b[0m\u001b[33m our\u001b[0m\u001b[33m Con\u001b[0m\u001b[33mfluence\u001b[0m\u001b[33m docs\u001b[0m\u001b[33m,\u001b[0m\u001b[33m is\u001b[0m\u001b[33m as\u001b[0m\u001b[33m follows\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m1\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Tr\u001b[0m\u001b[33muncate\u001b[0m\u001b[33m the\u001b[0m\u001b[33m Nginx\u001b[0m\u001b[33m access\u001b[0m\u001b[33m log\u001b[0m\u001b[33m file\u001b[0m\u001b[33m:\u001b[0m\u001b[33m `\u001b[0m\u001b[33mtruncate\u001b[0m\u001b[33m -\u001b[0m\u001b[33ms\u001b[0m\u001b[33m \u001b[0m\u001b[33m0\u001b[0m\u001b[33m /\u001b[0m\u001b[33mvar\u001b[0m\u001b[33m/log\u001b[0m\u001b[33m/nginx\u001b[0m\u001b[33m/access\u001b[0m\u001b[33m.log\u001b[0m\u001b[33m`\n",
      "\u001b[0m\u001b[33m2\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Run\u001b[0m\u001b[33m log\u001b[0m\u001b[33mrotate\u001b[0m\u001b[33m to\u001b[0m\u001b[33m rotate\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m:\u001b[0m\u001b[33m `\u001b[0m\u001b[33mlog\u001b[0m\u001b[33mrotate\u001b[0m\u001b[33m -\u001b[0m\u001b[33mf\u001b[0m\u001b[33m /\u001b[0m\u001b[33metc\u001b[0m\u001b[33m/log\u001b[0m\u001b[33mrotate\u001b[0m\u001b[33m.d\u001b[0m\u001b[33m/nginx\u001b[0m\u001b[33m`\n",
      "\u001b[0m\u001b[33m3\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Reload\u001b[0m\u001b[33m Nginx\u001b[0m\u001b[33m:\u001b[0m\u001b[33m `\u001b[0m\u001b[33msystem\u001b[0m\u001b[33mctl\u001b[0m\u001b[33m reload\u001b[0m\u001b[33m nginx\u001b[0m\u001b[33m`\n",
      "\n",
      "\u001b[0m\u001b[33mAdditionally\u001b[0m\u001b[33m,\u001b[0m\u001b[33m it\u001b[0m\u001b[33m is\u001b[0m\u001b[33m recommended\u001b[0m\u001b[33m to\u001b[0m\u001b[33m disable\u001b[0m\u001b[33m noisy\u001b[0m\u001b[33m logging\u001b[0m\u001b[33m and\u001b[0m\u001b[33m archive\u001b[0m\u001b[33m old\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m.\u001b[0m\u001b[33m To\u001b[0m\u001b[33m prevent\u001b[0m\u001b[33m such\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m future\u001b[0m\u001b[33m,\u001b[0m\u001b[33m it\u001b[0m\u001b[33m is\u001b[0m\u001b[33m suggested\u001b[0m\u001b[33m to\u001b[0m\u001b[33m:\n",
      "\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Set\u001b[0m\u001b[33m up\u001b[0m\u001b[33m disk\u001b[0m\u001b[33m alerts\u001b[0m\u001b[33m at\u001b[0m\u001b[33m \u001b[0m\u001b[33m70\u001b[0m\u001b[33m/\u001b[0m\u001b[33m85\u001b[0m\u001b[33m/\u001b[0m\u001b[33m95\u001b[0m\u001b[33m%\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Correct\u001b[0m\u001b[33m log\u001b[0m\u001b[33mrotate\u001b[0m\u001b[33m settings\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m*\u001b[0m\u001b[33m Use\u001b[0m\u001b[33m a\u001b[0m\u001b[33m separate\u001b[0m\u001b[33m partition\u001b[0m\u001b[33m for\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m.\u001b[0m\u001b[33m \n",
      "\n",
      "\u001b[0m\u001b[33mYou\u001b[0m\u001b[33m can\u001b[0m\u001b[33m find\u001b[0m\u001b[33m more\u001b[0m\u001b[33m information\u001b[0m\u001b[33m on\u001b[0m\u001b[33m this\u001b[0m\u001b[33m topic\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m Con\u001b[0m\u001b[33mfluence\u001b[0m\u001b[33m doc\u001b[0m\u001b[33m titled\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mDisk\u001b[0m\u001b[33m full\u001b[0m\u001b[33m on\u001b[0m\u001b[33m /\u001b[0m\u001b[33mvar\u001b[0m\u001b[33m causes\u001b[0m\u001b[33m \u001b[0m\u001b[33m500\u001b[0m\u001b[33ms\u001b[0m\u001b[33m &\u001b[0m\u001b[33m logging\u001b[0m\u001b[33m failures\u001b[0m\u001b[33m\".\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "turns = [\"Summarise the resolution for when Disk full on /var. Get the information from our Confluence docs.\"]\n",
    "for t in turns:\n",
    "    print(\"user>\", t)\n",
    "    stream = rag_agent.create_turn(\n",
    "        messages=[{\"role\": \"user\", \"content\": t}], session_id=session_id, stream=True\n",
    "    )\n",
    "    for event in AgentEventLogger().log(stream):\n",
    "        event.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b22240-c3e5-49ce-b06f-73444029e5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "fileHeader": "",
  "fileUid": "7da25939-a2a3-463c-958e-9cdfd710d158",
  "isAdHoc": false,
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
